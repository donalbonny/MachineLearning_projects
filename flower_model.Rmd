---
title: "flower_model"
author: "Vinh Pham"
date: "December 10, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(fig.align="center", fig.height=9, fig.width=10)
```

## Modeling Transcription binding contribution and gene expression

Domain-specific genes targeted by floral quartets that determine different floral organ identities. 

* Objective: to build the model to predict or to identify potential regulators affect domain specificity based on the expression changes between 2 domains. 
* Dataset: the expression changes between 2 different domains in different organ specific genes (i.e., sepals, petals, stamens, and carpels). Dataset from this analysis was obtained from the published data from Chen et al., 2018 and JiaoY et al.,2010. Based on domain-specific mRNA translatome data (JiaoY et al., 2010), Chen et al., 2018 identified 1013 organ-specific genes that were highly expressed either in AP1-specific (sepal), AG-specific (carpel), AP1/AP3-common (petal), or AP3/AG-common (stamen) domains

Floral quartet model of organ identity determination in Arabidopsis thaliana. 
![alt text](https://github.com/donalbonny/donalbonny.github.io/blob/master/assets/Picture1.png "Floral model")


```{r}
set.seed(2018)
data <-  read.csv("flower.csv", header = T)
head(data)
dim(data)
```


```{r}
sapply(data, class)
```
We will split dataset into train dataset (80% data) and validation dataset 

```{r}
library(caret)
validation_index <- createDataPartition(data$Cluster, p = 0.8, list = FALSE)
validation <- data[-validation_index,]
data <- data[validation_index,]
dim(data)

```

You now have training data in the dataset variable and a validation set we will use later in the validation variable.

```{r}
#Look at the cluster distribution
library(caret)
percentage <- prop.table(table(data$Cluster)) * 100
cbind(freq= table(data$Cluster), percentage = percentage)
```
So there are 5 different clusters: AG-Specific, AP1 specific, AP1-AP3, AP3 specific and AP3-AG that organ specific genes can be classified into

There are 6 features can be used to build the model: AP1-Stage 4, AP1-Stage6, AP3-Stage 4, AP3-Stage 6, AG-Stage 4, AG-Stage 6

```{r}
#statistical summary of data 
summary(data)
```

```{r}
#split the data input and output 
x = data[,2:7]
head(x)
y = data[,1]
head(y)
```
Let's check the distribution of the train data by plotting boxplot for x including the distribution of all 6 features. 

```{r}
par(mfrow=c(1,6))
  for(i in 1:6) {
  boxplot(x[,i], main=names(x)[i])
}
```
And the distribution of clusters


```{r}
plot(y)
```
Looks like this is imbalance data  since we have AP1-AP3 is the highest number among 6 different clusters. AP3-specific and AP3-AG has only 50, which is 1/3 of the number of AP1-AP3 cluster. 
This is called "Accuracy Paradox". It is the case where your accuracy measures tell the story that you have excellent accuracy (such as 90%), but the accuracy is only reflecting the underlying class distribution.

Next part, we should look at the following performance measures that can give more insight into the accuracy of the model than traditional classification accuracy:

- Confusion Matrix: A breakdown of predictions into a table showing correct predictions (the diagonal) and the types of incorrect predictions made (what classes incorrect predictions were assigned).
- Precision: A measure of a classifiers exactness.
- Recall: A measure of a classifiers completeness
- F1 Score (or F-score): A weighted average of precision and recall.

Also, take a look at the following:

- Kappa (or Cohen's kappa): Classification accuracy normalized by the imbalance of the classes in the data.
- ROC Curves: Like precision and recall, accuracy is divided into sensitivity and specificity and models can be chosen based on the balance thresholds of these values.


Now, we can also plot t-SNE (t-distributed stochastic neighbor embedding) plot showing expression profiles of organ-specific genes

```{r}

#tSNE
library(Rtsne)

set.seed(2018)
tsne <- Rtsne(x, dims = 3, perplexity=30, verbose=TRUE, max_iter = 500)

```

```{r}
colors = rainbow(length(unique(data$Cluster)))
names(colors) = unique(data$Cluster)
plot(tsne$Y, t='n', main="tSNE", xlab="tSNE dimension 1", ylab="tSNE dimension 2",  "cex.main"=2, "cex.lab"=1.5)
text(tsne$Y,col=colors[data$Cluster])

```
If you want to build the 3d tSNE plot, use can use plot3d function:
```{r}
#require(rgl)
#plot3d(tsne$Y, col=colors[data$Cluster])
#legend3d("topright", legend = '0':'5', pch = 16, col = rainbow(5))
```


```{r}
library("ellipse")
featurePlot(x=x, y=y, plot="ellipse", auto.key = list(columns = 2))
```


```{r}
featurePlot(x = x, y = y, plot = "box", auto.key = list(columns = 3))
```
```{r}
scales <- list(x=list(relation="free"), y=list(relation="free"))
featurePlot(x=x, y=y, plot="density", scales=scales)
```

We will 10-fold crossvalidation to estimate accuracy and We are using the metric of "Accuracy" to evaluate models.


```{r}
control <- trainControl(method="cv", number=10)
metric <- "Accuracy"
```


# Classfication problem, given 6 different attributes
## Objective:predict the class cluster) of any instance from the value of attributes. 

Let's evaluate different algorithms:

Classification and Regression Trees (CART).

k-Nearest Neighbors (kNN).

Random Forest (RF)

```{r}

# classification and decision tree 
set.seed(2018)
fit.cart <- train(Cluster~., data = data, method = "rpart", metric = metric, trControl = control)

#kNN k- Nearest Neighbors
set.seed(2018)
fit.knn <- train(Cluster~., data = data, method = "knn", metric = metric, trControl = control)

#random forest 
set.seed(2018)
fit.rf <- train(Cluster~., data= data, method="rf", metric=metric, trControl=control)
```
We can also plot the decission tree using rpart library

```{r}
library(rpart.plot)
par(mar=c(0.5,2, 0.5, 0.5))
tree <- rpart(Cluster~., data=data)

rpart.plot(tree,box.palette="RdBu", shadow.col="gray", cex = 0.75, main = "Classification Tree")
```


We can see the accuracy of each classifier and also other metrics like Kappa:



```{r}
result <-  resamples(list( cart = fit.cart, knn = fit.knn, rf = fit.rf))
summary(result)
```


Plot of the model evaluation results and compare the spread and the mean accuracy of each model.

```{r}
dotplot(result)
```

Random forest was the most accurate model. The result for random forest model can be summarised:

```{r}
print(fit.rf)
```
 
Now run the RF model directly on the validation set and summarize the results in a confusion matrix.
 
```{r}
prediction <- predict(fit.rf, validation)
confusionMatrix(prediction, validation$Cluster)
```

